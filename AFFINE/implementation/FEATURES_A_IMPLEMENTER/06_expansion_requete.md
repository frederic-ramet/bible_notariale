# üîç Am√©lioration #6 : Expansion de Requ√™te

[‚Üê Retour √† l'index](./00_INDEX.md)

---

## üìä Fiche technique

| Attribut | Valeur |
|----------|--------|
| **Priorit√©** | ‚ö° RAPIDE (Quick Win) |
| **Impact** | ‚≠ê‚≠ê‚≠ê‚≠ê (Am√©liore le rappel) |
| **Effort** | 0.5 jour |
| **Statut** | üìã √Ä faire |
| **D√©pendances** | #5 - Enrichissement m√©tadonn√©es (vocabulaire_specifique) |
| **Repo** | `application` |

---

## üéØ Probl√®me identifi√©

### Observations de l'audit

**Probl√®me** : Les utilisateurs utilisent des termes diff√©rents de ceux pr√©sents dans les documents

**Sympt√¥mes** :
- Utilisateur dit "CCN" ‚Üí Document dit "Convention Collective Nationale"
- Utilisateur dit "cong√©s" ‚Üí Document dit "cong√©s pay√©s" ou "cong√©s annuels"
- Utilisateur dit "formation" ‚Üí Document dit "formation professionnelle continue"

**Impact mesur√©** :
- Perte de **20-30%** de documents pertinents
- Recherche vectorielle rate les synonymes exacts
- Utilisateurs doivent reformuler pour obtenir de bons r√©sultats

**Exemple concret** :

```
Question : "Quelle est la CCN applicable ?"

‚ùå Recherche actuelle (sans expansion) :
Embedding(question) = [0.2, 0.8, ...]
‚Üí Ne trouve que les docs contenant "CCN"
‚Üí Rate les docs disant "Convention Collective Nationale du Notariat"

‚úÖ Recherche avec expansion :
Question expans√©e : "Quelle est la CCN Convention Collective Nationale IDCC 2205 applicable ?"
Embedding(question_expans√©e) = [0.3, 0.9, ...]
‚Üí Trouve TOUS les documents (CCN + Convention Collective + IDCC 2205)
‚Üí Meilleur rappel
```

---

## üí° Solution propos√©e

### Vue d'ensemble

**Expansion de requ√™te en 2 modes** :

1. **Expansion par synonymes** : Utiliser `vocabulaire_specifique` des m√©tadonn√©es
2. **Expansion s√©mantique** : G√©n√©rer variantes avec LLM (optionnel)

### Architecture

```mermaid
graph LR
    A[Question utilisateur] --> B[Extracteur de termes]
    B --> C{Terme dans vocabulaire ?}
    C -->|Oui| D[Ajouter synonymes]
    C -->|Non| E[Garder terme original]
    D --> F[Question expans√©e]
    E --> F
    F --> G[Embedding]
    G --> H[Recherche vectorielle]
```

---

## üîß Impl√©mentation d√©taill√©e

### Pr√©requis : Vocabulaire disponible

Le fichier `_metadata/index_complet.json` (bible_notariale) contient d√©j√† le vocabulaire :

```json
{
  "vocabulaire_specifique": [
    {
      "terme": "CCN",
      "synonymes": ["Convention Collective Nationale", "Convention Collective du Notariat", "IDCC 2205"],
      "definition": "Convention collective applicable aux √©tudes notariales"
    },
    {
      "terme": "OPCO",
      "synonymes": ["OPCO EP", "Op√©rateur de Comp√©tences"],
      "definition": "Organisme de financement de la formation professionnelle"
    }
  ]
}
```

Ce vocabulaire a √©t√© enrichi dans l'am√©lioration #5 (d√©j√† fait).

---

### Modifications repo `application`

#### 1. Nouveau fichier : `services/query_expander.py`

```python
"""
Service d'expansion de requ√™te
Utilise le vocabulaire_specifique des m√©tadonn√©es
"""

import json
import re
from typing import List, Dict, Set
from pathlib import Path


class QueryExpander:
    """
    Expanse les requ√™tes en ajoutant synonymes et variantes
    """

    def __init__(self, vocabulary_path: str = None):
        """
        Initialize avec le vocabulaire sp√©cifique

        Args:
            vocabulary_path: Chemin vers index_complet.json
        """
        self.vocabulary_path = vocabulary_path or Path(__file__).parent.parent / "data" / "index_complet.json"
        self.term_to_synonyms = {}
        self._load_vocabulary()

    def _load_vocabulary(self):
        """
        Charge le vocabulaire depuis les m√©tadonn√©es
        """
        try:
            with open(self.vocabulary_path, 'r', encoding='utf-8') as f:
                index_data = json.load(f)

            # Extraire tous les vocabulaires de tous les documents
            all_vocab = set()
            for doc in index_data.get('documents', []):
                vocab = doc.get('vocabulaire_specifique', [])
                for item in vocab:
                    if isinstance(item, dict):
                        all_vocab.add(json.dumps(item, ensure_ascii=False))

            # Convertir en dictionnaire terme ‚Üí synonymes
            for vocab_json in all_vocab:
                vocab_item = json.loads(vocab_json)
                terme = vocab_item.get('terme', '').strip()
                synonymes = vocab_item.get('synonymes', [])

                if terme and synonymes:
                    # Normaliser (minuscules)
                    terme_norm = terme.lower()

                    # Ajouter terme + tous ses synonymes
                    all_variants = [terme] + synonymes

                    self.term_to_synonyms[terme_norm] = all_variants

            print(f"‚úÖ Vocabulaire charg√© : {len(self.term_to_synonyms)} termes")

        except Exception as e:
            print(f"‚ùå Erreur chargement vocabulaire : {e}")
            self.term_to_synonyms = {}

    def expand_query(self, query: str, max_synonyms_per_term: int = 2) -> str:
        """
        Expanse la requ√™te en ajoutant les synonymes

        Args:
            query: Question de l'utilisateur
            max_synonyms_per_term: Nombre max de synonymes √† ajouter par terme (√©viter requ√™tes trop longues)

        Returns:
            Question expans√©e
        """
        # 1. Normaliser la requ√™te
        query_lower = query.lower()

        # 2. Trouver les termes pr√©sents dans le vocabulaire
        terms_found = []
        for term in self.term_to_synonyms.keys():
            # Recherche du terme (entier, pas substring)
            if re.search(r'\b' + re.escape(term) + r'\b', query_lower):
                terms_found.append(term)

        # 3. Pour chaque terme trouv√©, ajouter synonymes
        synonyms_to_add = []
        for term in terms_found:
            synonyms = self.term_to_synonyms[term]

            # Limiter le nombre de synonymes ajout√©s
            synonyms_to_add.extend(synonyms[:max_synonyms_per_term])

        # 4. Construire la requ√™te expans√©e
        if synonyms_to_add:
            # Ajouter les synonymes √† la fin de la requ√™te
            expanded_query = f"{query} ({' '.join(synonyms_to_add)})"
        else:
            expanded_query = query

        return expanded_query

    def expand_query_detailed(self, query: str) -> Dict:
        """
        Expanse la requ√™te et retourne les d√©tails

        Returns:
            {
                'original': str,
                'expanded': str,
                'terms_found': List[str],
                'synonyms_added': List[str]
            }
        """
        query_lower = query.lower()

        # Trouver termes
        terms_found = []
        synonyms_added = []

        for term in self.term_to_synonyms.keys():
            if re.search(r'\b' + re.escape(term) + r'\b', query_lower):
                terms_found.append(term)
                synonyms = self.term_to_synonyms[term]
                synonyms_added.extend(synonyms[:2])

        # Construire expansion
        if synonyms_added:
            expanded_query = f"{query} ({' '.join(synonyms_added)})"
        else:
            expanded_query = query

        return {
            'original': query,
            'expanded': expanded_query,
            'terms_found': terms_found,
            'synonyms_added': synonyms_added
        }


# Mode 2 (optionnel) : Expansion s√©mantique avec LLM
class SemanticQueryExpander:
    """
    Expansion s√©mantique avec LLM (g√©n√®re des variantes de la question)
    """

    def __init__(self, openai_client):
        self.client = openai_client

    async def expand_semantic(self, query: str) -> List[str]:
        """
        G√©n√®re des variantes s√©mantiques de la question

        Returns:
            Liste de 3-5 reformulations
        """
        prompt = f"""G√©n√®re 3 reformulations diff√©rentes de cette question, en gardant le m√™me sens :

Question originale : "{query}"

Reformulations (une par ligne) :
"""

        response = await self.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            max_tokens=200
        )

        variants = response.choices[0].message.content.strip().split('\n')
        variants = [v.strip('- ').strip() for v in variants if v.strip()]

        return variants
```

---

#### 2. Modification : `services/notaria_rag_service.py`

```python
"""
Int√©gration de l'expansion de requ√™te dans le RAG
"""

from services.query_expander import QueryExpander

class NotariaRAGService:

    def __init__(self):
        # ... autres initialisations
        self.query_expander = QueryExpander()

    async def search(self, question: str, domain: str = None) -> List[dict]:
        """
        Recherche avec expansion de requ√™te

        Args:
            question: Question de l'utilisateur
            domain: Domaine m√©tier (RH, DEONTOLOGIE, ASSURANCES)

        Returns:
            Liste de chunks pertinents
        """

        # 1. Expanse la requ√™te
        expansion_result = self.query_expander.expand_query_detailed(question)

        expanded_query = expansion_result['expanded']

        print(f"üîç Question originale : {question}")
        print(f"üîç Question expans√©e : {expanded_query}")
        print(f"üìù Termes trouv√©s : {expansion_result['terms_found']}")
        print(f"‚ûï Synonymes ajout√©s : {expansion_result['synonyms_added']}")

        # 2. Cr√©er l'embedding de la question EXPANS√âE
        embedding = await self.embedding_service.embed(expanded_query)

        # 3. Recherche vectorielle dans Neo4j
        query = """
        CALL db.index.vector.queryNodes('chunk_embeddings', $top_k, $embedding)
        YIELD node, score
        """

        if domain:
            query += """
            MATCH (node)-[:PART_OF]->(doc:Document)
            WHERE $domain IN doc.domaines_metier
            """

        query += """
        RETURN node.text as text,
               node.doc_titre as doc_titre,
               node.doc_id as doc_id,
               score
        ORDER BY score DESC
        LIMIT $top_k
        """

        results = await self.neo4j.run(query, {
            'embedding': embedding,
            'top_k': 20,
            'domain': domain
        })

        return results
```

---

#### 3. Tests : `tests/test_query_expander.py`

```python
"""
Tests pour l'expansion de requ√™te
"""

import pytest
from services.query_expander import QueryExpander

@pytest.fixture
def expander():
    """Cr√©er un expander avec vocabulaire de test"""
    expander = QueryExpander()

    # Mock vocabulary pour tests
    expander.term_to_synonyms = {
        'ccn': ['Convention Collective Nationale', 'Convention Collective du Notariat', 'IDCC 2205'],
        'opco': ['OPCO EP', 'Op√©rateur de Comp√©tences'],
        'clerc': ['clerc de notaire', 'collaborateur salari√©'],
        'rcp': ['Responsabilit√© Civile Professionnelle', 'assurance RC pro']
    }

    return expander

def test_expand_query_with_known_term(expander):
    """Test expansion avec terme connu"""

    query = "Quelle est la CCN applicable ?"

    expanded = expander.expand_query(query)

    # V√©rifier que les synonymes sont ajout√©s
    assert "Convention Collective Nationale" in expanded
    assert "CCN" in expanded  # Terme original conserv√©

def test_expand_query_multiple_terms(expander):
    """Test expansion avec plusieurs termes"""

    query = "La CCN pr√©voit-elle un financement OPCO pour les clercs ?"

    result = expander.expand_query_detailed(query)

    # V√©rifier termes trouv√©s
    assert 'ccn' in result['terms_found']
    assert 'opco' in result['terms_found']
    assert 'clerc' in result['terms_found']

    # V√©rifier synonymes ajout√©s
    assert len(result['synonyms_added']) > 0

    # V√©rifier que la requ√™te est expans√©e
    assert result['expanded'] != result['original']

def test_expand_query_no_known_terms(expander):
    """Test expansion sans terme connu"""

    query = "Comment faire une vente immobili√®re ?"

    result = expander.expand_query_detailed(query)

    # Pas de termes trouv√©s
    assert result['terms_found'] == []
    assert result['synonyms_added'] == []

    # Requ√™te inchang√©e
    assert result['expanded'] == result['original']

def test_expand_query_case_insensitive(expander):
    """Test que l'expansion est insensible √† la casse"""

    query1 = "Quelle est la CCN ?"
    query2 = "Quelle est la ccn ?"
    query3 = "Quelle est la Ccn ?"

    expanded1 = expander.expand_query(query1)
    expanded2 = expander.expand_query(query2)
    expanded3 = expander.expand_query(query3)

    # Toutes les variantes doivent produire le m√™me r√©sultat
    assert "Convention Collective Nationale" in expanded1
    assert "Convention Collective Nationale" in expanded2
    assert "Convention Collective Nationale" in expanded3

def test_max_synonyms_limit(expander):
    """Test que le nombre de synonymes est limit√©"""

    query = "Quelle est la CCN ?"

    # Limite √† 1 synonyme
    expanded = expander.expand_query(query, max_synonyms_per_term=1)

    # Compter les synonymes ajout√©s
    synonyms = expander.term_to_synonyms['ccn']

    # Seulement 1 doit √™tre ajout√©
    synonyms_in_expanded = [s for s in synonyms if s in expanded]
    assert len(synonyms_in_expanded) <= 1

@pytest.mark.asyncio
async def test_semantic_expansion():
    """Test expansion s√©mantique avec LLM"""

    from services.query_expander import SemanticQueryExpander
    from openai import AsyncOpenAI

    client = AsyncOpenAI()
    expander = SemanticQueryExpander(client)

    query = "Combien de cong√©s pay√©s ai-je ?"

    variants = await expander.expand_semantic(query)

    # V√©rifier qu'on a des variantes
    assert len(variants) >= 3

    # V√©rifier qu'elles sont diff√©rentes de l'original
    assert all(v != query for v in variants)

    # V√©rifier qu'elles contiennent des mots-cl√©s similaires
    keywords = ['cong√©s', 'pay√©s']
    assert any(any(kw in v.lower() for kw in keywords) for v in variants)
```

---

## üìä M√©triques et monitoring

### M√©triques √† collecter

```python
"""
M√©triques expansion de requ√™te
"""

from dataclasses import dataclass

@dataclass
class ExpansionMetrics:
    """M√©triques d'expansion"""

    original_query: str
    expanded_query: str
    terms_found: int
    synonyms_added: int
    expansion_ratio: float  # len(expanded) / len(original)

    # Impact sur la recherche
    results_without_expansion: int
    results_with_expansion: int
    new_results_found: int  # Combien de nouveaux docs trouv√©s gr√¢ce √† l'expansion ?

async def compare_with_without_expansion(
    query: str,
    rag_service
) -> ExpansionMetrics:
    """
    Compare les r√©sultats avec et sans expansion
    """

    # Sans expansion
    results_without = await rag_service.search(query, expand=False)

    # Avec expansion
    expansion_result = rag_service.query_expander.expand_query_detailed(query)
    results_with = await rag_service.search(query, expand=True)

    # Calculer nouveaux r√©sultats
    doc_ids_without = {r['doc_id'] for r in results_without}
    doc_ids_with = {r['doc_id'] for r in results_with}
    new_results = doc_ids_with - doc_ids_without

    return ExpansionMetrics(
        original_query=query,
        expanded_query=expansion_result['expanded'],
        terms_found=len(expansion_result['terms_found']),
        synonyms_added=len(expansion_result['synonyms_added']),
        expansion_ratio=len(expansion_result['expanded']) / len(query),
        results_without_expansion=len(results_without),
        results_with_expansion=len(results_with),
        new_results_found=len(new_results)
    )
```

---

## ‚úÖ Tests et validation

### Plan de test

| Test | Question | Expansion attendue |
|------|----------|-------------------|
| **T1** | "Quelle est la CCN ?" | + "Convention Collective Nationale" |
| **T2** | "Financement OPCO formation" | + "OPCO EP", "Op√©rateur de Comp√©tences" |
| **T3** | "Cong√©s pay√©s clerc" | + "clerc de notaire", "collaborateur salari√©" |
| **T4** | "Assurance RCP" | + "Responsabilit√© Civile Professionnelle" |
| **T5** | "Vente immobili√®re" | Pas d'expansion (hors vocabulaire) |

### Validation manuelle

```bash
# 1. Tester l'expansion seule
python3 -c "
from services.query_expander import QueryExpander
expander = QueryExpander()

query = 'Quelle est la CCN applicable ?'
result = expander.expand_query_detailed(query)

print('Original:', result['original'])
print('Expans√©e:', result['expanded'])
print('Termes trouv√©s:', result['terms_found'])
print('Synonymes ajout√©s:', result['synonyms_added'])
"

# 2. Tester l'impact sur la recherche
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{
    "question": "Quelle est la CCN applicable ?",
    "session_id": "test_expansion",
    "debug": true
  }'

# V√©rifier dans les logs :
# - Question expans√©e affich√©e
# - Nombre de r√©sultats trouv√©s
# - Nouveaux documents trouv√©s gr√¢ce √† l'expansion
```

---

## üîÑ Rollback

### Si l'expansion d√©grade les performances

**Sympt√¥mes** :
- Requ√™tes trop longues (>500 caract√®res)
- Temps de recherche augment√©
- R√©sultats moins pertinents (trop de bruit)

**Proc√©dure de rollback** :

```python
# Dans notaria_rag_service.py

async def search(self, question: str, domain: str = None, expand: bool = False):
    """
    Ajouter flag expand pour d√©sactiver facilement
    """

    if expand:
        # Expansion activ√©e
        expanded_query = self.query_expander.expand_query(question)
    else:
        # Expansion d√©sactiv√©e
        expanded_query = question

    # Continue...
```

**Configuration** :
```python
# Dans config.py
ENABLE_QUERY_EXPANSION = False  # Mettre √† False pour d√©sactiver
```

---

## üìà Impact attendu

### Avant am√©lioration

- ‚ùå Recherche uniquement sur termes exacts
- ‚ùå Rate 20-30% des documents pertinents
- ‚ùå Utilisateurs doivent reformuler

### Apr√®s am√©lioration

- ‚úÖ Recherche sur termes + synonymes
- ‚úÖ Meilleur rappel (+20-30% documents trouv√©s)
- ‚úÖ Moins de reformulations n√©cessaires

### M√©triques cibles

| M√©trique | Avant | Cible |
|----------|-------|-------|
| Rappel (% docs pertinents trouv√©s) | 70% | >90% |
| Questions n√©cessitant reformulation | 30% | <10% |
| Nouveaux docs trouv√©s par expansion | 0 | +5 par requ√™te |

---

## üìÖ Planning d'impl√©mentation

### Jour 1 (matin - 2h)

**9h-10h : D√©veloppement**
- ‚úÖ Cr√©er `services/query_expander.py`
- ‚úÖ Impl√©menter QueryExpander
- ‚úÖ Charger vocabulaire depuis index_complet.json

**10h-11h : Int√©gration**
- ‚úÖ Modifier `notaria_rag_service.py`
- ‚úÖ Ajouter expand_query_detailed() avant embedding

### Jour 1 (apr√®s-midi - 2h)

**14h-15h : Tests**
- ‚úÖ √âcrire tests unitaires
- ‚úÖ Tester sur 20 questions validation
- ‚úÖ Mesurer impact (rappel avant/apr√®s)

**15h-16h : D√©ploiement**
- ‚úÖ D√©ployer en staging
- ‚úÖ Tester manuellement
- ‚úÖ Monitoring expansion

**Total** : 0.5 jour (4h)

---

## üöÄ D√©ploiement

### Checklist pr√©-d√©ploiement

- [ ] Vocabulaire charg√© correctement
- [ ] Expansion test√©e sur 20 questions
- [ ] Rappel am√©lior√© mesur√© (+20% minimum)
- [ ] Pas de d√©gradation temps de recherche
- [ ] Tests unitaires passent
- [ ] Flag ENABLE_QUERY_EXPANSION configurable

### √âvolutions futures (optionnelles)

**Mode 2 : Expansion s√©mantique LLM**
- G√©n√©rer 3-5 reformulations de la question
- Chercher avec toutes les variantes
- Fusionner les r√©sultats (RRF - Reciprocal Rank Fusion)

**Mode 3 : Expansion apprise**
- Analyser les logs de recherche
- Identifier automatiquement nouveaux synonymes
- Enrichir le vocabulaire_specifique

---

## üéØ Crit√®res de succ√®s

### Crit√®res obligatoires

1. ‚úÖ **Rappel am√©lior√©** : +20% de documents pertinents trouv√©s
2. ‚úÖ **Pas de d√©gradation** : Temps de recherche <3s
3. ‚úÖ **Vocabulaire charg√©** : 100% des termes disponibles

### Crit√®res souhaitables

4. ‚úÖ Moins de reformulations utilisateur (<10% questions)
5. ‚úÖ Satisfaction utilisateur stable ou am√©lior√©e

---

[‚Üê Retour √† l'index](./00_INDEX.md) | [Am√©lioration suivante : Questions typiques ‚Üí](./07_questions_typiques.md)
