# üï∏Ô∏è Am√©lioration #12 : DENSIFYER (Graph Densifier)

[‚Üê Retour √† l'index](../00_INDEX.md)

---

## üìä Fiche technique

| Attribut | Valeur |
|----------|--------|
| **Priorit√©** | üü° LONG TERME |
| **Impact** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (Scalabilit√© + Qualit√© recherche) |
| **Effort** | 3 jours |
| **Statut** | üìã √Ä faire |
| **D√©pendances** | #8 - Ontologie restaur√©e |
| **Repo** | `application` + `bible_notariale` |
| **Source** | üí° Proposition Julien (Expert Graph RAG) |

---

## üéØ Probl√®me identifi√© (Analyse Julien)

### Observations

**Probl√®me** : Le syst√®me extrait des entit√©s brutes sans lien logique

**Citation de Julien** :
> "Actuellement, le pipeline d'ingestion Notaria extrait des entit√©s brutes.
> Exemple : Il trouve "Bail pr√©caire", "Convention d'occupation", "Bail d√©rogatoire".
> Probl√®me : Pour le syst√®me, ce sont trois objets diff√©rents. Il n'y a pas de lien logique.
> Cons√©quence : Si on cherche "Bail commercial", on rate ces documents."

**Impact** :
- ‚ùå **Dette s√©mantique** : Ontologie doit √™tre maintenue manuellement
- ‚ùå **Recherche limit√©e** : Pas d'alias automatiques entre concepts
- ‚ùå **Scalabilit√© bloqu√©e** : Impossible d'ing√©rer massivement sans chaos s√©mantique

**Exemple concret** :

```
Ingestion actuelle (entit√©s orphelines) :

[Bail pr√©caire] (orphelin)
[Convention d'occupation] (orphelin)
[Bail d√©rogatoire] (orphelin)

Question utilisateur : "Qu'est-ce qu'un bail commercial ?"
‚Üí ‚ùå Ne trouve RIEN (aucun lien s√©mantique)

---

Avec DENSIFYER (relations cr√©√©es automatiquement) :

[Bail pr√©caire] --[EST_UN_TYPE_DE]--> [Bail commercial] --[APPARTIENT_A]--> [Droit Immobilier]
[Convention d'occupation] --[EST_UN_TYPE_DE]--> [Bail commercial]
[Bail d√©rogatoire] --[SYNONYME_DE]--> [Bail commercial d√©rogatoire]

Question utilisateur : "Qu'est-ce qu'un bail commercial ?"
‚Üí ‚úÖ Trouve tous les documents pertinents via le graphe
```

---

## üí° Solution propos√©e (Julien)

### Vue d'ensemble

**DENSIFYER** = Agent autonome qui tourne en t√¢che de fond pour :
1. D√©tecter les entit√©s "orphelines" dans Neo4j
2. Utiliser un LLM pour les classer dans l'ontologie
3. Cr√©er automatiquement les relations hi√©rarchiques
4. G√©n√©rer des alias pour am√©liorer la recherche

### Architecture

```mermaid
graph LR
    A[Harvesting] --> B[D√©tection entit√©s orphelines]
    B --> C[Reasoning LLM]
    C --> D[Classification ontologique]
    D --> E[Graph Injection]
    E --> F[Validation CSV]
    F --> G{Validation humaine}
    G -->|OK| H[Relations permanentes]
    G -->|KO| I[Correction manuelle]
```

---

## üîß Impl√©mentation d√©taill√©e

### Objectifs cibles (Julien)

> **R√©duction de la dette s√©mantique** : Plus besoin de maintenir l'ontologie √† la main. Le syst√®me apprend des documents qu'il ing√®re.
>
> **Performance de recherche** : Gr√¢ce aux alias g√©n√©r√©s par le Densifyer, si un utilisateur tape "compromis", le syst√®me trouve les documents parlant de "promesse synallagmatique de vente".
>
> **Scalabilit√©** : On peut ing√©rer 10 000 documents ; le Densifyer nettoiera le bazar s√©mantique automatiquement la nuit.

---

### Phase 1 : Harvesting (D√©tection des orphelins)

#### Script : `services/graph_densifyer/harvester.py`

```python
"""
Harvester : D√©tecte les entit√©s orphelines dans Neo4j
"""

from neo4j import AsyncGraphDatabase
from typing import List, Dict


class OrphanHarvester:
    """
    Identifie les n≈ìuds orphelins (entit√©s non reli√©es √† l'ontologie)
    """

    def __init__(self, neo4j_driver):
        self.driver = neo4j_driver

    async def find_orphan_entities(self) -> List[Dict]:
        """
        Trouve tous les concepts/entit√©s extraits mais non reli√©s √† l'ontologie

        Returns:
            Liste de {entity_name, entity_type, doc_sources}
        """

        async with self.driver.session() as session:
            # Requ√™te 1 : Entit√©s mentionn√©es dans documents mais pas dans ontologie
            result = await session.run("""
                // Trouver tous les termes mentionn√©s dans les documents
                MATCH (d:Document)-[:MENTIONNE]->(t:Terme)

                // Exclure ceux qui ont d√©j√† une classification ontologique
                WHERE NOT EXISTS {
                    MATCH (t)-[:EST_UN_TYPE_DE|APPARTIENT_A|SYNONYME_DE]->(:Terme)
                }
                AND NOT EXISTS {
                    MATCH (t)<-[:INCLUT]-(:Thematique)
                }

                // Compter les documents sources
                WITH t, count(DISTINCT d) as doc_count, collect(DISTINCT d.titre) as sources

                RETURN t.name as entity_name,
                       t.type as entity_type,
                       doc_count,
                       sources[..5] as sample_sources
                ORDER BY doc_count DESC
                LIMIT 1000
            """)

            orphans = []
            async for record in result:
                orphans.append({
                    'entity_name': record['entity_name'],
                    'entity_type': record['entity_type'],
                    'doc_count': record['doc_count'],
                    'sample_sources': record['sample_sources']
                })

            print(f"üîç Harvesting : {len(orphans)} entit√©s orphelines d√©tect√©es")

            return orphans

    async def get_entity_context(self, entity_name: str) -> Dict:
        """
        R√©cup√®re le contexte d'une entit√© pour aider la classification

        Returns:
            {
                'entity_name': str,
                'contexts': List[str],  # Phrases o√π l'entit√© appara√Æt
                'co_occurring_terms': List[str]  # Termes fr√©quemment associ√©s
            }
        """

        async with self.driver.session() as session:
            # R√©cup√©rer contextes d'utilisation
            result = await session.run("""
                MATCH (t:Terme {name: $entity_name})<-[:MENTIONNE]-(d:Document)
                MATCH (d)-[:CONTAINS]->(c:Chunk)
                WHERE c.text CONTAINS $entity_name

                RETURN c.text as context
                LIMIT 10
            """, entity_name=entity_name)

            contexts = []
            async for record in result:
                contexts.append(record['context'][:500])  # Limiter longueur

            # R√©cup√©rer termes co-occurrents
            result = await session.run("""
                MATCH (t1:Terme {name: $entity_name})<-[:MENTIONNE]-(d:Document)-[:MENTIONNE]->(t2:Terme)
                WHERE t1 <> t2

                WITH t2, count(*) as co_count
                ORDER BY co_count DESC
                LIMIT 10

                RETURN t2.name as term
            """, entity_name=entity_name)

            co_occurring = []
            async for record in result:
                co_occurring.append(record['term'])

            return {
                'entity_name': entity_name,
                'contexts': contexts,
                'co_occurring_terms': co_occurring
            }
```

---

### Phase 2 : Reasoning (Classification LLM)

#### Script : `services/graph_densifyer/reasoner.py`

```python
"""
Reasoner : Utilise LLM pour classifier les entit√©s orphelines
"""

from typing import Dict, List
import json


class OntologyReasoner:
    """
    Utilise un LLM pour classifier automatiquement les entit√©s
    """

    def __init__(self, openai_client, ontology_schema: Dict):
        """
        Args:
            openai_client: Client OpenAI
            ontology_schema: Structure de l'ontologie (domaines, th√©matiques, concepts)
        """
        self.client = openai_client
        self.ontology_schema = ontology_schema

    async def classify_entity(
        self,
        entity_name: str,
        entity_context: Dict
    ) -> Dict:
        """
        Classifie une entit√© orpheline dans l'ontologie

        Returns:
            {
                'entity_name': str,
                'parent_concept': str,  # Concept parent dans l'ontologie
                'relation_type': str,   # EST_UN_TYPE_DE, SYNONYME_DE, etc.
                'confidence': float,    # 0-1
                'explanation': str
            }
        """

        # Construire le prompt de classification
        prompt = self._build_classification_prompt(entity_name, entity_context)

        # Appeler LLM
        response = await self.client.chat.completions.create(
            model="gpt-4o",  # Mod√®le fort pour classification
            messages=[
                {"role": "system", "content": DENSIFYER_SYSTEM_PROMPT},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,
            max_tokens=300
        )

        # Parser r√©ponse JSON
        try:
            classification = json.loads(response.choices[0].message.content.strip())
        except json.JSONDecodeError:
            classification = {
                'entity_name': entity_name,
                'parent_concept': None,
                'relation_type': None,
                'confidence': 0.0,
                'explanation': 'Erreur parsing LLM'
            }

        return classification

    def _build_classification_prompt(
        self,
        entity_name: str,
        entity_context: Dict
    ) -> str:
        """
        Construit le prompt de classification
        """

        # Formatter les contextes
        contexts_formatted = "\n".join([
            f"- {ctx[:200]}..."
            for ctx in entity_context.get('contexts', [])[:3]
        ])

        # Formatter les termes co-occurrents
        co_terms = ", ".join(entity_context.get('co_occurring_terms', [])[:10])

        # Formatter l'ontologie disponible
        ontology_formatted = self._format_ontology_schema()

        prompt = f"""Classifie cette entit√© juridique dans l'ontologie notariale.

**Entit√© √† classifier** : "{entity_name}"

**Contextes d'utilisation** :
{contexts_formatted}

**Termes fr√©quemment associ√©s** :
{co_terms}

**Ontologie disponible** :
{ontology_formatted}

Ta mission : D√©terminer o√π cette entit√© se situe dans l'ontologie.

R√©ponds UNIQUEMENT avec un JSON dans ce format :

{{
  "entity_name": "{entity_name}",
  "parent_concept": "Nom du concept parent dans l'ontologie",
  "relation_type": "EST_UN_TYPE_DE | SYNONYME_DE | APPARTIENT_A",
  "confidence": <score 0-1>,
  "explanation": "Justification en 1 phrase"
}}

Si l'entit√© ne correspond √† rien dans l'ontologie, mets parent_concept: null.
"""

        return prompt

    def _format_ontology_schema(self) -> str:
        """
        Formate l'ontologie pour le prompt
        """

        lines = []

        for domaine, thematiques in self.ontology_schema.get('thematiques', {}).items():
            lines.append(f"\n**Domaine : {domaine}**")

            for thematique in thematiques[:10]:  # Limiter
                termes = self.ontology_schema.get('termes', {}).get(thematique, [])
                termes_str = ", ".join(termes[:5])
                lines.append(f"  - Th√©matique : {thematique} (termes: {termes_str})")

        return "\n".join(lines)


# System prompt pour le Densifyer
DENSIFYER_SYSTEM_PROMPT = """Tu es un expert en droit notarial et en classification ontologique.

Ta mission : Classifier des concepts juridiques notariaux dans une ontologie structur√©e.

**Types de relations possibles** :

1. **EST_UN_TYPE_DE** : L'entit√© est un type sp√©cifique d'un concept plus g√©n√©ral
   - Ex: "Bail pr√©caire" EST_UN_TYPE_DE "Bail commercial"

2. **SYNONYME_DE** : L'entit√© est un synonyme ou une formulation alternative
   - Ex: "Compromis de vente" SYNONYME_DE "Promesse synallagmatique de vente"

3. **APPARTIENT_A** : L'entit√© appartient √† un domaine/th√©matique
   - Ex: "Vente en l'√©tat futur d'ach√®vement" APPARTIENT_A "Droit Immobilier"

**R√®gles** :
- Si l'entit√© ne correspond √† aucun concept ontologique existant, retourne parent_concept: null
- Score de confiance : 1.0 = certain, 0.5 = probable, <0.3 = incertain
- Sois rigoureux : ne force pas une classification douteuse
"""
```

---

### Phase 3 : Graph Injection

#### Script : `services/graph_densifyer/injector.py`

```python
"""
Graph Injector : √âcrit les relations dans Neo4j
"""

from typing import List, Dict
from neo4j import AsyncGraphDatabase


class GraphInjector:
    """
    Injecte les classifications dans le graphe Neo4j
    """

    def __init__(self, neo4j_driver):
        self.driver = neo4j_driver

    async def inject_classification(
        self,
        classification: Dict,
        min_confidence: float = 0.7
    ) -> bool:
        """
        Injecte une classification dans Neo4j

        Args:
            classification: R√©sultat du Reasoner
            min_confidence: Seuil de confiance minimum

        Returns:
            True si inject√©, False si rejet√© (confiance trop faible)
        """

        # Filtrer par confiance
        if classification.get('confidence', 0) < min_confidence:
            print(f"‚ö†Ô∏è  Confiance trop faible pour {classification['entity_name']} ({classification['confidence']})")
            return False

        entity_name = classification['entity_name']
        parent = classification.get('parent_concept')
        relation_type = classification.get('relation_type')

        if not parent or not relation_type:
            return False

        # Injecter dans Neo4j
        async with self.driver.session() as session:
            await session.run(f"""
                MATCH (entity:Terme {{name: $entity_name}})
                MERGE (parent:Terme {{name: $parent}})
                MERGE (entity)-[:{relation_type}]->(parent)

                SET entity.densifyer_classified = true,
                    entity.densifyer_confidence = $confidence,
                    entity.densifyer_explanation = $explanation
            """,
                entity_name=entity_name,
                parent=parent,
                confidence=classification.get('confidence'),
                explanation=classification.get('explanation')
            )

        print(f"‚úÖ Inject√© : {entity_name} --[{relation_type}]--> {parent}")

        return True

    async def inject_batch(
        self,
        classifications: List[Dict],
        min_confidence: float = 0.7
    ) -> Dict:
        """
        Injecte un batch de classifications

        Returns:
            {
                'injected': int,
                'rejected': int,
                'errors': int
            }
        """

        stats = {'injected': 0, 'rejected': 0, 'errors': 0}

        for classification in classifications:
            try:
                if await self.inject_classification(classification, min_confidence):
                    stats['injected'] += 1
                else:
                    stats['rejected'] += 1
            except Exception as e:
                print(f"‚ùå Erreur injection {classification.get('entity_name')}: {e}")
                stats['errors'] += 1

        return stats
```

---

### Phase 4 : Validation CSV

#### Script : `services/graph_densifyer/validator.py`

```python
"""
Validator : G√©n√®re CSV pour validation humaine
"""

import csv
from pathlib import Path
from typing import List, Dict


class DensifyerValidator:
    """
    G√©n√®re fichiers CSV pour validation humaine des classifications
    """

    def __init__(self, output_dir: str = "validations"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)

    def generate_validation_csv(
        self,
        classifications: List[Dict],
        output_filename: str = "densifyer_validations.csv"
    ):
        """
        G√©n√®re un CSV pour validation humaine

        Format CSV :
        | Entity | Parent Concept | Relation | Confidence | Explanation | Validation | Commentaires |
        """

        output_path = self.output_dir / output_filename

        with open(output_path, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=[
                'Entity',
                'Parent_Concept',
                'Relation_Type',
                'Confidence',
                'Explanation',
                'Validation',  # √Ä remplir par l'humain (OK / KO)
                'Commentaires'  # √Ä remplir par l'humain
            ])

            writer.writeheader()

            for classification in classifications:
                writer.writerow({
                    'Entity': classification.get('entity_name'),
                    'Parent_Concept': classification.get('parent_concept'),
                    'Relation_Type': classification.get('relation_type'),
                    'Confidence': f"{classification.get('confidence', 0):.2f}",
                    'Explanation': classification.get('explanation', ''),
                    'Validation': '',  # √Ä remplir
                    'Commentaires': ''  # √Ä remplir
                })

        print(f"üìù CSV de validation g√©n√©r√© : {output_path}")

        return output_path
```

---

### Orchestrateur principal

#### Script : `services/graph_densifyer/densifyer_agent.py`

```python
"""
Densifyer Agent : Orchestrateur principal du processus de densification
"""

import asyncio
from datetime import datetime
from typing import Dict


class DensifyerAgent:
    """
    Agent autonome de densification du graphe
    """

    def __init__(
        self,
        neo4j_driver,
        openai_client,
        ontology_schema: Dict
    ):
        from .harvester import OrphanHarvester
        from .reasoner import OntologyReasoner
        from .injector import GraphInjector
        from .validator import DensifyerValidator

        self.harvester = OrphanHarvester(neo4j_driver)
        self.reasoner = OntologyReasoner(openai_client, ontology_schema)
        self.injector = GraphInjector(neo4j_driver)
        self.validator = DensifyerValidator()

    async def run_densification_cycle(
        self,
        max_orphans: int = 100,
        min_confidence: float = 0.7
    ) -> Dict:
        """
        Ex√©cute un cycle complet de densification

        Returns:
            Statistiques du cycle
        """

        print(f"\nüöÄ D√©but du cycle de densification - {datetime.now()}")

        # 1. Harvesting
        print("\nüì° Phase 1 : Harvesting...")
        orphans = await self.harvester.find_orphan_entities()

        if not orphans:
            print("‚úÖ Aucune entit√© orpheline d√©tect√©e")
            return {'orphans': 0}

        # Limiter le nombre d'orphelins trait√©s
        orphans_to_process = orphans[:max_orphans]
        print(f"üìä {len(orphans_to_process)} entit√©s orphelines √† traiter")

        # 2. Reasoning (avec concurrence)
        print("\nüß† Phase 2 : Reasoning...")
        classifications = []

        # Traiter par batches pour ne pas surcharger l'API
        batch_size = 10
        for i in range(0, len(orphans_to_process), batch_size):
            batch = orphans_to_process[i:i+batch_size]

            batch_tasks = []
            for orphan in batch:
                # R√©cup√©rer contexte
                context = await self.harvester.get_entity_context(orphan['entity_name'])

                # Classifier
                task = self.reasoner.classify_entity(orphan['entity_name'], context)
                batch_tasks.append(task)

            # Ex√©cuter batch en parall√®le
            batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)

            for result in batch_results:
                if isinstance(result, Exception):
                    print(f"‚ùå Erreur reasoning : {result}")
                else:
                    classifications.append(result)

            print(f"  ‚úì Batch {i//batch_size + 1} trait√©")

        # 3. Graph Injection
        print("\nüíâ Phase 3 : Graph Injection...")
        injection_stats = await self.injector.inject_batch(classifications, min_confidence)

        print(f"  ‚úì Inject√© : {injection_stats['injected']}")
        print(f"  ‚ö†Ô∏è  Rejet√© : {injection_stats['rejected']}")
        print(f"  ‚ùå Erreurs : {injection_stats['errors']}")

        # 4. G√©n√©ration CSV validation
        print("\nüìù Phase 4 : G√©n√©ration CSV validation...")
        csv_path = self.validator.generate_validation_csv(
            classifications,
            output_filename=f"densifyer_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        )

        print(f"\n‚úÖ Cycle termin√© - {datetime.now()}")

        return {
            'orphans_detected': len(orphans),
            'orphans_processed': len(orphans_to_process),
            'classifications': len(classifications),
            **injection_stats,
            'csv_path': str(csv_path)
        }


# Fonction pour ex√©cuter en t√¢che de fond (cron)
async def run_nightly_densification():
    """
    T√¢che de fond ex√©cut√©e la nuit
    """

    from neo4j import AsyncGraphDatabase
    from openai import AsyncOpenAI
    import json

    # Charger ontologie
    with open('data/ontology.json', 'r') as f:
        ontology_schema = json.load(f)

    # Initialiser clients
    neo4j_driver = AsyncGraphDatabase.driver(
        "bolt://localhost:7687",
        auth=("neo4j", "password")
    )

    openai_client = AsyncOpenAI()

    # Lancer agent
    agent = DensifyerAgent(neo4j_driver, openai_client, ontology_schema)

    stats = await agent.run_densification_cycle(
        max_orphans=200,
        min_confidence=0.7
    )

    await neo4j_driver.close()

    print(f"\nüìä Statistiques finales : {stats}")


if __name__ == '__main__':
    asyncio.run(run_nightly_densification())
```

---

## üìä Configuration Cron (t√¢che de fond)

```bash
# Ajouter au crontab pour ex√©cution nocturne
# Tous les jours √† 2h du matin

0 2 * * * cd /app && python3 services/graph_densifyer/densifyer_agent.py >> logs/densifyer.log 2>&1
```

---

## üìà Impact attendu (Julien)

### Avant am√©lioration

- ‚ùå Entit√©s orphelines non reli√©es
- ‚ùå Recherche limit√©e aux termes exacts
- ‚ùå Maintenance ontologie 100% manuelle
- ‚ùå Scalabilit√© bloqu√©e

### Apr√®s am√©lioration

- ‚úÖ **Relations automatiques** : "Bail pr√©caire" ‚Üí "Bail commercial"
- ‚úÖ **Alias intelligents** : "Compromis" trouve "Promesse synallagmatique"
- ‚úÖ **Scalabilit√©** : 10 000 documents ing√©r√©s sans chaos s√©mantique
- ‚úÖ **Maintenance r√©duite** : Le syst√®me apprend automatiquement

### Gains mesurables

| M√©trique | Avant | Cible |
|----------|-------|-------|
| Entit√©s orphelines | 500+ | <50 |
| Rappel (recherche avec synonymes) | 60% | >85% |
| Temps maintenance ontologie | 5h/semaine | <1h/semaine |

---

## üìÖ Planning d'impl√©mentation

**Total** : 3 jours

### Jour 1 (8h)

- ‚úÖ Cr√©er `harvester.py` (d√©tection orphelins)
- ‚úÖ Cr√©er `reasoner.py` (classification LLM)
- ‚úÖ Tests unitaires harvesting + reasoning

### Jour 2 (8h)

- ‚úÖ Cr√©er `injector.py` (injection graphe)
- ‚úÖ Cr√©er `validator.py` (g√©n√©ration CSV)
- ‚úÖ Tests d'injection

### Jour 3 (8h)

- ‚úÖ Cr√©er `densifyer_agent.py` (orchestrateur)
- ‚úÖ Configuration cron
- ‚úÖ Premier cycle complet de densification
- ‚úÖ Validation humaine CSV

---

## üéØ Crit√®res de succ√®s

### Crit√®res obligatoires

1. ‚úÖ **D√©tection orphelins** : 100% des entit√©s non reli√©es identifi√©es
2. ‚úÖ **Classification** : >70% de confiance moyenne
3. ‚úÖ **Validation CSV** : G√©n√©r√©e pour chaque cycle
4. ‚úÖ **Ex√©cution autonome** : Fonctionne en cron nocturne

### Crit√®res souhaitables

5. ‚úÖ R√©duction entit√©s orphelines >80% apr√®s 1 mois
6. ‚úÖ Validation humaine <20% de rejets
7. ‚úÖ Am√©lioration rappel recherche +25%

---

[‚Üê Retour √† l'index](../00_INDEX.md) | [Am√©lioration suivante : ReAct Agent ‚Üí](./13_react_agent.md)
