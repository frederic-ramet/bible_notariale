# üìÑ RAPPORT D'AUDIT ET FEUILLE DE ROUTE DE REM√âDIATION TECHNIQUE

## 1. SYNTH√àSE

L'audit de l'architecture actuelle r√©v√®le que la couche ontologique n'est pas exploit√©e dans la version actuelle. Il s'agit, √† l'heure actuelle, d'une recherche vectorielle na√Øve qui expose le syst√®me √† des hallucinations juridiques (m√©lange de contextes, anachronismes r√©glementaires...).

Pour garantir la fiabilit√© requise par la profession notariale, il est imp√©ratif de restaurer l'architecture "Double Helix" (Vecteur + Graphe Ontologique) initialement con√ßue. Ce plan d'action en 5 √©tapes vise √† r√©introduire la structuration s√©mantique et le contr√¥le temporel.

---

## 2. PLAN D'IMPL√âMENTATION D√âTAILL√â DES QWICK-WINS

### √âTAPE 1 : Restauration et extension de la dorsale ontologique
**Objectif :** Transformer l'ontologie passive (`.owl`) en filtre actif de recherche.

**Action :**
1.  **R√©int√©gration :** Le fichier `notaria_ontology.owl` ne doit plus √™tre un simple dictionnaire de synonymes. Il doit d√©finir la taxonomie stricte des documents.
2.  **Extension des domaines :** Ajouter une classe racine `DomaineMetier` dans l'ontologie pour segmenter le corpus.
    *   *Classes :* `DroitImmobilier`, `DroitDeLaFamille`, `DroitDesSocietes`, `Fiscalite`, `Deontologie`.
    *   *Propri√©t√©s :* `est_regi_par`, `appartient_au_domaine`.

**Impl√©mentation Technique (Neo4j / OntologyService) :**
```cypher
// Injection de la taxonomie dans le Graph
MERGE (d:Domaine {nom: "DroitImmobilier"})
MERGE (c:Concept {nom: "Vente en l'√©tat futur d'ach√®vement"})
MERGE (c)-[:APPARTIENT_A]->(d)
// Les documents ing√©r√©s devront √™tre li√©s √† ces n≈ìuds Domaines
```

---

### √âTAPE 2 : Chunking S√©mantique (Context-Aware)
**Objectif :** Arr√™ter le d√©coupage arbitraire (512 tokens) qui brise l'unit√© l√©gale des articles.

**Action :** Utiliser la structure d√©tect√©e par `Docling` pour un d√©coupage intelligent.
1.  **Unit√© Atomique :** 1 Article de loi = 1 Chunk. 1 Clause de contrat = 1 Chunk.
2.  **Enrichissement du Chunk :** Chaque chunk doit porter en m√©tadonn√©es son chemin hi√©rarchique (ex: "Titre I > Chapitre 2 > Section 4 > Article 12").

**Impl√©mentation (Python) :**
```python
# Au lieu de split par tokens, on split par structure logique
def semantic_chunking(document_structure):
    chunks = []
    for section in document_structure.sections:
        # Le contexte parent est inject√© dans le texte du chunk pour l'embedding
        context_header = f"{document.title} > {section.path}"
        chunk_content = f"{context_header}\n{section.text}"
        chunks.append(Chunk(content=chunk_content, meta={"type": "Article"}))
    return chunks
```

---

### √âTAPE 3 : Filtrage temporel strict (Time-Travel Logic)
**Objectif :** Emp√™cher le RAG de citer des textes abrog√©s ou futurs.

**Action :**
1.  **M√©tadonn√©es Temporelles :** Chaque n≈ìud `Document` et `Chunk` dans Neo4j re√ßoit les attributs : `validity_start`, `validity_end`, `status` (VIGUEUR/ABROGE).
2.  **Injection au Query Time :** Le moteur de recherche doit accepter un param√®tre `reference_date`.

_√† voir pour les documents sans date !_
**Impl√©mentation (Cypher) :**
```cypher
// Filtre dur avant la recherche vectorielle
MATCH (d:Document)-[:CONTAINS]->(c:Chunk)
WHERE d.validity_start <= $query_date 
  AND (d.validity_end IS NULL OR d.validity_end >= $query_date)
// Seulement ensuite, on calcule la similarit√© vectorielle sur ces chunks
CALL db.index.vector.queryNodes('chunk_embeddings', 10, $embedding) 
YIELD node AS c, score
```

---

### √âTAPE 4 : Connexion Neuro-Symbolique (ReAct + Ontologie)
**Objectif :** Le cerveau (Agent ReAct) doit consulter la carte (Ontologie) avant de marcher.

**Action :** Modifier le `notaria_rag_service.py`.
1.  **Reasoning (√âtape 1) :** L'agent analyse la question pour extraire les concepts cl√©s.
2.  **Ontology Lookup (√âtape 2) :** L'agent interroge l'`OntologyService` pour savoir √† quel `Domaine` appartiennent ces concepts.
3.  **Targeted Retrieval (√âtape 3) :** La recherche vectorielle est confin√©e au sous-graphe du domaine identifi√©.

**Workflow de l'Agent :**
> *Utilisateur :* "Quel d√©lai pour la SRU ?"
> *Agent (Reason) :* "SRU" -> Concept identifi√©.
> *Ontologie :* "SRU" appartient au domaine "DroitImmobilier".
> *Agent (Act) :* Ex√©cute la recherche vectorielle UNIQUEMENT sur les n≈ìuds √©tiquet√©s `DroitImmobilier`.

---

### √âTAPE 5 : Automatisation du "Tribunal" (LLM-as-a-Judge)
**Objectif :** Remplacer la validation humaine fastidieuse par une √©valuation massive et continue.

**Action :** D√©ployer un pipeline d'√©valuation automatis√© utilisant un mod√®le √† large fen√™tre contextuelle et hautes capacit√©s de raisonnement (ex : Gemini 1.5 Pro ou GPT-4o) pour agir comme "Juge Supr√™me".

**Crit√®res d'√©valuation du Juge (Prompt Syst√®me) :**
1.  **Exactitude Juridique :** La r√©ponse contredit-elle les textes fournis ?
2.  **Respect Temporel :** Les textes cit√©s √©taient-ils en vigueur √† la date de r√©f√©rence ?
3.  **Compl√©tude :** Manque-t-il une clause d'exclusion mentionn√©e dans le contrat source ?

**Output Automatis√© :**
G√©n√©ration d'un rapport de conformit√© (Score /100) √† chaque modification du code ou de la base documentaire, bloquant le d√©ploiement en cas de r√©gression du score de fiabilit√©.

---

## 3. PLAN D'IMPL√âMENTATION D√âTAILL√â DU "DENSIFYER"

Actuellement, le pipeline d'ingestion Notaria extrait des entit√©s brutes.
    Exemple : Il trouve "Bail pr√©caire", "Convention d'occupation", "Bail d√©rogatoire".
    Probl√®me : Pour le syst√®me, ce sont trois objets diff√©rents. Il n'y a pas de lien logique.
    Cons√©quence : Si on cherche "Bail commercial", on rate ces documents.

**La proposition DENSIFYER :** C'est un agent autonome qui tourne en t√¢che de fond. Il prend les entit√©s orphelines, demande √† un LLM de les classer dans l'ontologie, et cr√©e les relations hi√©rarchiques.

**R√©sultat apr√®s densification :** Bail pr√©caire --[EST_UN_TYPE_DE]--> Bail commercial --[APPARTIENT_A]--> Droit Immobilier.

Objectif cible : 
    - R√©duction de la dette s√©mantique : Plus besoin de maintenir l'ontologie √† la main. Le syst√®me apprend des documents qu'il ing√®re.
    - Performance de recherche : Gr√¢ce aux alias g√©n√©r√©s par le Densifyer, si un utilisateur tape "compromis", le syst√®me trouve les documents parlant de "promesse synallagmatique de vente".
    - Scalabilit√© : On peut ing√©rer 10 000 documents ; le Densifyer nettoiera le bazar s√©mantique automatiquement la nuit.

#### Architecture

    1. Harvesting : Identification des n≈ìuds "orphelins" dans Neo4j (entit√©s extraites mais non reli√©es √† l'ontologie).
    2. Reasoning (densification) : Envoi au LLM (GPT-0SS-20B ou mod√®le mini) avec un set de prompts adapt√© au type d'extraction choisi : droit notarial, recherche de dates, recherche de personnes... Le but est d'extraire les documents et les informations sous diff√©rents angles/perspectives.
    3. Graph injection : √âcriture des relations canoniques et des alias dans Neo4j.
    4. Validation : G√©n√©ration du fichier CSV pour validation humaine ou via le Tribunal.


---

## 4. OPTIMISATION VECTOR SEARCH PAR M√âTADONN√âES 

Les m√©tadonn√©es offrent un gain r√©el de pertinence si elles sont utilis√©es pour structurer l'espace vectoriel et le contexte. Le post-filtering s'est montr√© d√©cevant dans la majorit√© des projets RAG, toute la subtilit√© est dans la structure de l'information et le ciblage de l'information.

#### Probl√®me :
Si tu embeddes le texte brut : "Article 12 : Le mandataire r√©pond de celui qu'il s'est substitu√©."
Le vecteur est g√©n√©rique. Il y a des "Article 12" dans le Code Civil, le Code de Commerce, le RPN... Le RAG va se perdre.

La Solution (Metadata Injection) :
On injecte la hi√©rarchie (m√©tadonn√©e structurelle) directement dans le texte qui est vectoris√©.

#### Impl√©mentation :
Au lieu d'embedder chunk.text, tu embeddes :

```python
# Format: [M√©tadonn√©e 1] [M√©tadonn√©e 2] > Contenu
vector_input = f"Contexte: {doc.titre} > {chapitre.titre} > Article {article.num} | Contenu: {chunk.text}"
```

    R√©sultat : Le vecteur "sait" math√©matiquement qu'il appartient au Code Civil.
    Performance : La s√©paration s√©mantique dans l'espace vectoriel est drastiquement am√©lior√©e.

---

## 5. PR√â-FILTRAGE HYBRIDE (HARD FILTERING) POUR LE GRAPH

Au lieu d'utiliser les m√©tadonn√©es (Date, Cat√©gorie, Juridiction) apr√®s la recherche pour trier les r√©sultats (post-processing), nous les utilisons avant pour restreindre l'espace de recherche vectoriel.

#### Impl√©mentation technique (Neo4j)

Nous basculons d'une recherche purement vectorielle √† une ex√©cution en deux temps au sein de la m√™me requ√™te Cypher :

    - Phase 1 (Symbolique) : Identification du sous-graphe pertinent via l'agent "REASON".
    Exemple : Si la question concerne "La fiscalit√© en 2024", le moteur isole instantan√©ment les n≈ìuds Document tagu√©s FISCALIT√â et dont la date_validit√© couvre 2024.

    - Phase 2 (Vectorielle) : L'algorithme KNN (K-Nearest Neighbors) n'est ex√©cut√© que sur les chunks li√©s √† ce sous-graphe r√©duit.

#### Gains Attendus

- Performance : Vitesse de recherche multipli√©e par 10 sur les gros volumes (on ne scanne pas l'inutile).
- Fiabilit√© : √âlimination math√©matique des hallucinations li√©es √† des documents hors p√©rim√®tre (ex : confondre une r√®gle RH et une r√®gle immobili√®re).

---

## 6. PARENT DOCUMENT RETRIEVER

Il existe une contradiction fondamentale dans le RAG :
- Pour chercher, il faut des fragments courts et pr√©cis (Micro-Chunks).
- Pour r√©pondre, le LLM a besoin de paragraphes entiers et structur√©s (Macro-Chunks).

Le "Parent Retriever" d√©couple ces deux besoins. Nous allons restructurer le stockage dans Neo4j :

    N≈ìud Parent (Macro-Chunk) : Stocke une section compl√®te (ex : un article de loi entier, une clause contractuelle compl√®te). Il n'est pas vectoris√© pour la recherche.

    N≈ìuds Enfants (Micro-Chunks) : Le Parent est d√©coup√© en 3 ou 4 phrases cl√©s. Ce sont elles qui sont vectoris√©es.

    Relation : (Child)-[:PART_OF]->(Parent).

#### Workflow au Runtime

    Le syst√®me cherche les vecteurs les plus proches parmi les Enfants (tr√®s haute pr√©cision).

    Au lieu de renvoyer l'enfant, le syst√®me remonte la relation [:PART_OF] pour r√©cup√©rer le Parent.

    Le LLM re√ßoit le Parent complet.

#### Gains Attendus

- Coh√©rence Juridique : Le LLM ne travaille plus sur des phrases tronqu√©es mais sur des unit√©s l√©gales compl√®tes.
- Pr√©cision : On d√©tecte des nuances fines (gr√¢ce aux petits chunks) sans perdre la vue d'ensemble.

---

## Perspectives

Une fois ces fondations pos√©es, nous ouvrirons la voie √† une √©tape cl√© : le Graph Clustering (d√©tection de communaut√©s). Passer du stockage de l'information √† la d√©couverte de connaissances.

En utilisant les algorithmes de Graph Data Science (GDS) de Neo4j (comme l'algorithme de Louvain), nous pourrons laisser le syst√®me d√©couvrir lui-m√™me des liens th√©matiques non explicites.

    Exemple : Le syst√®me d√©tectera que les documents parlant de "Panneaux photovolta√Øques" (Immobilier) sont souvent li√©s s√©mantiquement aux "Baux emphyt√©otiques" (Droit rural), cr√©ant des m√©ta-cat√©gories dynamiques pour sugg√©rer des connexions invisibles aux notaires juniors.

Je bosse dessus, c'est encore early de mon c√¥t√© !